{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfce8061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T11:39:43.822944Z",
     "iopub.status.busy": "2021-09-03T11:39:43.822944Z",
     "iopub.status.idle": "2021-09-03T11:39:48.198549Z",
     "shell.execute_reply": "2021-09-03T11:39:48.198549Z",
     "shell.execute_reply.started": "2021-09-03T11:39:43.822944Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: mxnet\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd\n",
    "import math\n",
    "from relgraphconv import *\n",
    "from utils import *\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from model import *\n",
    "import dgl\n",
    "plt.style.use('science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36bf5e3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T11:39:48.199449Z",
     "iopub.status.busy": "2021-09-03T11:39:48.199449Z",
     "iopub.status.idle": "2021-09-03T11:39:48.484833Z",
     "shell.execute_reply": "2021-09-03T11:39:48.484833Z",
     "shell.execute_reply.started": "2021-09-03T11:39:48.199449Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1130\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "mx.random.seed(seed)\n",
    "dgl.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cc60483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T11:39:48.486828Z",
     "iopub.status.busy": "2021-09-03T11:39:48.485831Z",
     "iopub.status.idle": "2021-09-03T11:39:55.226297Z",
     "shell.execute_reply": "2021-09-03T11:39:55.225420Z",
     "shell.execute_reply.started": "2021-09-03T11:39:48.485831Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Anaconda\\envs\\jie_zeng\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 80\n",
      "number of edges: 715\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "matfn = 'adjacency_matrix_13.mat'\n",
    "g, tratim_matrix = load_adjmatrix(matfn)\n",
    "edge_type = np.load(\n",
    "    'edge_type_13.npy')\n",
    "edge_type = mx.nd.array(edge_type, ctx=mx.gpu())\n",
    "train_x = np.load('train_x.npy')\n",
    "train_y = np.load('train_y.npy')\n",
    "valid_x = np.load('valid_x.npy')\n",
    "valid_y = np.load('valid_y.npy')\n",
    "test_x = np.load('test_x.npy')\n",
    "test_y = np.load('test_y.npy')\n",
    "\n",
    "train_x = np.swapaxes(train_x, 1, 2)\n",
    "train_x = np.concatenate([train_x[:, :, :, 0], train_x[:, :, :, 1]], axis=2)\n",
    "train_y = np.swapaxes(train_y, 1, 2)\n",
    "train_y = np.concatenate([train_y[:, :, :, 0], train_y[:, :, :, 1]], axis=2)\n",
    "\n",
    "valid_x = np.swapaxes(valid_x, 1, 2)\n",
    "valid_x = np.concatenate([valid_x[:, :, :, 0], valid_x[:, :, :, 1]], axis=2)\n",
    "valid_y = np.swapaxes(valid_y, 1, 2)\n",
    "valid_y = np.concatenate([valid_y[:, :, :, 0], valid_y[:, :, :, 1]], axis=2)\n",
    "\n",
    "test_x = np.swapaxes(test_x, 1, 2)\n",
    "test_x = np.concatenate([test_x[:, :, :, 0], test_x[:, :, :, 1]], axis=2)\n",
    "test_y = np.swapaxes(test_y, 1, 2)\n",
    "test_y = np.concatenate([test_y[:, :, :, 0], test_y[:, :, :, 1]], axis=2)\n",
    "\n",
    "scaler_axis = (0, 1, 2)\n",
    "scaler = StandardScaler(mean=train_x.mean(axis=scaler_axis),\n",
    "                        std=train_x.std(axis=scaler_axis))\n",
    "train_x = nd.array(train_x, ctx=mx.gpu())\n",
    "train_y = nd.array(train_y, ctx=mx.gpu())\n",
    "valid_x = nd.array(valid_x, ctx=mx.gpu())\n",
    "valid_y = nd.array(valid_y, ctx=mx.gpu())\n",
    "test_x = nd.array(test_x, ctx=mx.gpu())\n",
    "test_y = nd.array(test_y, ctx=mx.gpu())\n",
    "\n",
    "train_x = scaler.transform(train_x)\n",
    "train_y = scaler.transform(train_y)\n",
    "valid_x = scaler.transform(valid_x)\n",
    "valid_y = scaler.transform(valid_y)\n",
    "test_x = scaler.transform(test_x)\n",
    "test_y = scaler.transform(test_y)\n",
    "\n",
    "num_train = train_x.shape[0]\n",
    "num_valid = valid_x.shape[0]\n",
    "num_test = test_x.shape[0]\n",
    "\n",
    "num_entra = tratim_matrix.shape[0]\n",
    "seq_len = 4\n",
    "pre_len = 4\n",
    "\n",
    "# divide training set, valid set and test set\n",
    "trainset = GraphTraffic(num_train, num_entra, tratim_matrix)\n",
    "validset = GraphTraffic(num_valid, num_entra, tratim_matrix)\n",
    "testset = GraphTraffic(num_test, num_entra, tratim_matrix)\n",
    "\n",
    "for i in range(trainset.__len__()):\n",
    "    trainset.graphs[i].ndata['h'] = train_x[i]\n",
    "    trainset.graphs[i].edata['type'] = edge_type.reshape(-1, )\n",
    "    trainset.labels[i] = train_y[i]\n",
    "for i in range(validset.__len__()):\n",
    "    validset.graphs[i].ndata['h'] = valid_x[i]\n",
    "    validset.graphs[i].edata['type'] = edge_type.reshape(-1, )\n",
    "    validset.labels[i] = valid_y[i]\n",
    "for i in range(testset.__len__()):\n",
    "    testset.graphs[i].ndata['h'] = test_x[i]\n",
    "    testset.graphs[i].edata['type'] = edge_type.reshape(-1, )\n",
    "    testset.labels[i] = test_y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc327c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T11:39:55.227295Z",
     "iopub.status.busy": "2021-09-03T11:39:55.226297Z",
     "iopub.status.idle": "2021-09-03T11:39:55.638224Z",
     "shell.execute_reply": "2021-09-03T11:39:55.637208Z",
     "shell.execute_reply.started": "2021-09-03T11:39:55.227295Z"
    }
   },
   "outputs": [],
   "source": [
    "num_hidden = 224\n",
    "inter_channel = 96\n",
    "dropout = 0.05\n",
    "n_hidden = num_hidden\n",
    "in_feats = 2 * seq_len\n",
    "num_classes = 2 * pre_len\n",
    "lr = 1e-3\n",
    "weight_decay = 0.0\n",
    "n_bases = -1\n",
    "n_layers = 1\n",
    "n_epochs = 1\n",
    "num_rels = 25\n",
    "use_self_loop = True\n",
    "batch_size = 32\n",
    "test_batch_size = 8\n",
    "# create model\n",
    "model = SARGCN(in_feats,\n",
    "               n_hidden,\n",
    "               num_classes,\n",
    "               num_rels,\n",
    "               num_bases=n_bases,\n",
    "               num_hidden_layers=n_layers,\n",
    "               dropout=dropout,\n",
    "               use_self_loop=use_self_loop,\n",
    "               gpu_id=mx.gpu(),\n",
    "               residual=False)\n",
    "model.initialize(mx.init.Xavier(magnitude=math.sqrt(2.0)), ctx=mx.gpu())\n",
    "trainer = gluon.Trainer(model.collect_params(),\n",
    "                        'adam',\n",
    "                        {'learning_rate': lr,\n",
    "                         'wd': weight_decay})\n",
    "loss = gluon.loss.L2Loss()\n",
    "stopper = EarlyStopping(patience=15)\n",
    "mx.random.seed(seed)\n",
    "train_iter = gluon.data.DataLoader(trainset, batch_size, shuffle=False,\n",
    "                                   batchify_fn=collate, last_batch='discard',\n",
    "                                   num_workers=512, thread_pool=True)\n",
    "mx.random.seed(seed)\n",
    "valid_iter = gluon.data.DataLoader(validset, test_batch_size, shuffle=False,\n",
    "                                   batchify_fn=collate, last_batch='discard',\n",
    "                                   num_workers=512, thread_pool=True)\n",
    "mx.random.seed(seed)\n",
    "test_iter = gluon.data.DataLoader(testset, test_batch_size, shuffle=False,\n",
    "                                  batchify_fn=collate, last_batch='discard',\n",
    "                                  num_workers=512, thread_pool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfdc01af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T11:39:55.638224Z",
     "iopub.status.busy": "2021-09-03T11:39:55.638224Z",
     "iopub.status.idle": "2021-09-03T11:40:12.744536Z",
     "shell.execute_reply": "2021-09-03T11:40:12.744536Z",
     "shell.execute_reply.started": "2021-09-03T11:39:55.638224Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Anaconda\\envs\\jie_zeng\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: DGLGraph.__len__ is deprecated.Please directly call DGLGraph.number_of_nodes.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | running time 15.52 s | train loss 8032.139 | valid loss 2960.285 | test loss 9520.906 | test rmse 137.992\n"
     ]
    }
   ],
   "source": [
    "TrainLoss, ValidLoss, TestLoss = [], [], []\n",
    "for epoch in range(n_epochs):\n",
    "    train_l_sum, n = 0.0, 0\n",
    "    start_time = time.time()\n",
    "    for iter, (bg, label) in enumerate(train_iter):\n",
    "        model.g = bg\n",
    "        with mx.autograd.record():\n",
    "            edge_type = bg.edata['type']\n",
    "            pred = model(bg, bg.ndata['h'], edge_type, None)\n",
    "            l = loss(pred, label)\n",
    "        l.backward()\n",
    "        trainer.step(batch_size)\n",
    "        train_l_sum += l\n",
    "        n += bg.__len__()\n",
    "    train_l = train_l_sum\n",
    "    train_rmse, train_loss = rmse_trainset(model, train_iter, batch_size, num_entra, scaler)\n",
    "    valid_rmse, valid_loss = rmse_testset(model, valid_iter, test_batch_size, num_entra, scaler)\n",
    "    test_rmse, test_loss = rmse_testset(model, test_iter, test_batch_size, num_entra, scaler)\n",
    "    print(\n",
    "        'epoch %d | running time %.2f s | train loss %.3f | valid loss %.3f | test loss %.3f | test rmse %.3f' %\n",
    "        (epoch + 1, time.time() - start_time, train_loss, valid_loss, test_loss, test_rmse))\n",
    "    TrainLoss.append(train_loss)\n",
    "    ValidLoss.append(valid_loss)\n",
    "    TestLoss.append(test_loss)\n",
    "    if stopper.step(valid_loss, model):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eb549c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T11:52:35.491467Z",
     "iopub.status.busy": "2021-09-03T11:52:35.491467Z",
     "iopub.status.idle": "2021-09-03T11:52:37.129698Z",
     "shell.execute_reply": "2021-09-03T11:52:37.127733Z",
     "shell.execute_reply.started": "2021-09-03T11:52:35.491467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 min, rmse: 36.413, mae: 22.599, mape: 0.14460\n",
      "time: 30 min, rmse: 38.358, mae: 23.633, mape: 0.15164\n",
      "time: 45 min, rmse: 39.488, mae: 24.489, mape: 0.16504\n",
      "time: 60 min, rmse: 42.436, mae: 25.740, mape: 0.19270\n"
     ]
    }
   ],
   "source": [
    "model.load_parameters('pre_trained_model.param')\n",
    "test = mx.nd.zeros(shape=(len(test_iter) * batch_size, num_entra, 8), ctx=mx.gpu())\n",
    "pred = mx.nd.zeros(shape=(len(test_iter) * batch_size, num_entra, 8), ctx=mx.gpu())\n",
    "count = 0\n",
    "for iter, (bg, label) in enumerate(test_iter):\n",
    "    y = label\n",
    "    edge_type = bg.edata['type']\n",
    "    _ = model(bg, bg.ndata['h'], edge_type, None)\n",
    "    test[count: count + len(label), :] = scaler.inverse_transform(y)\n",
    "    pred[count: count + len(label), :] = scaler.inverse_transform(_).reshape(-1, num_entra, 8)\n",
    "    count += len(label)\n",
    "\n",
    "test = test.asnumpy()\n",
    "pred = pred.asnumpy()\n",
    "for i in range(4):\n",
    "    test_ = test[:, :, [i, i+4]]\n",
    "    pred_ = pred[:, :, [i, i+4]]\n",
    "    rmse = masked_rmse_np(test_, pred_)\n",
    "    mae = masked_mae_np(test_, pred_)\n",
    "    mape = masked_mape_np(test_, pred_)\n",
    "    print('time: %d min, rmse: %.3f, mae: %.3f, mape: %.5f' % ((i+1)*15, rmse, mae, mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde8216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jie_zeng",
   "language": "python",
   "name": "jie_zeng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
